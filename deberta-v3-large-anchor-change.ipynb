{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73d41179",
   "metadata": {
    "papermill": {
     "duration": 0.022969,
     "end_time": "2022-06-19T02:53:31.210457",
     "exception": false,
     "start_time": "2022-06-19T02:53:31.187488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "Guide: Baseline Guide<br>\n",
    "Inference: USPPPM: DeBERTa V3 Small [Inference]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a300dc",
   "metadata": {
    "papermill": {
     "duration": 0.02183,
     "end_time": "2022-06-19T02:53:31.255888",
     "exception": false,
     "start_time": "2022-06-19T02:53:31.234058",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e29e83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:31.345399Z",
     "iopub.status.busy": "2022-06-19T02:53:31.340863Z",
     "iopub.status.idle": "2022-06-19T02:53:35.028568Z",
     "shell.execute_reply": "2022-06-19T02:53:35.027859Z",
     "shell.execute_reply.started": "2022-06-19T01:55:19.135421Z"
    },
    "papermill": {
     "duration": 3.744904,
     "end_time": "2022-06-19T02:53:35.028717",
     "exception": false,
     "start_time": "2022-06-19T02:53:31.283813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -q -y transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31d80ffa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:35.082612Z",
     "iopub.status.busy": "2022-06-19T02:53:35.081808Z",
     "iopub.status.idle": "2022-06-19T02:53:39.817021Z",
     "shell.execute_reply": "2022-06-19T02:53:39.816343Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.768171Z"
    },
    "papermill": {
     "duration": 4.76503,
     "end_time": "2022-06-19T02:53:39.817152",
     "exception": false,
     "start_time": "2022-06-19T02:53:35.052122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/torch-components-library/torch-components-main\")\n",
    "sys.path.append(\"../input/transformers/src\")\n",
    "sys.path.append(\"../input/mixout-github-code/mixout\")\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from torch_components import Configuration as Config, Timer, Averager\n",
    "from torch_components.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from torch_components.utils import seed_everything, get_lr, get_optimizer, get_scheduler\n",
    "from torch_components.import_utils import wandb_run_exists\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from mixout import MixLinear, Mixout\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display\n",
    "from datetime import timedelta\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import gc\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "\n",
    "os.environ[\"EXPERIMENT_NAME\"] = \"microsoft/deberta-v3-large\"\n",
    "\n",
    "EXPERIMENT_NAME = os.environ.get(\"EXPERIMENT_NAME\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "WANDB = False\n",
    "DEBUG = True\n",
    "USER_SECRETS = UserSecretsClient()\n",
    "\n",
    "\n",
    "if WANDB:\n",
    "    os.environ[\"WANDB_PROJECT\"] = \"uspppm\"\n",
    "    os.environ[\"WANDB_ENTITY\"] = \"uspppm\"\n",
    "    os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "    \n",
    "    wandb_secret_name = \"wandb_api_key\"\n",
    "    wandb_key = USER_SECRETS.get_secret(wandb_secret_name)\n",
    "    \n",
    "    EXPERIMENT_NAME = EXPERIMENT_NAME if EXPERIMENT_NAME != \"none\" else wandb.util.generate_id()\n",
    "    wandb.login(key=wandb_key)\n",
    "    \n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c31263f",
   "metadata": {
    "papermill": {
     "duration": 0.022396,
     "end_time": "2022-06-19T02:53:39.861905",
     "exception": false,
     "start_time": "2022-06-19T02:53:39.839509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6936dc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:39.913783Z",
     "iopub.status.busy": "2022-06-19T02:53:39.908589Z",
     "iopub.status.idle": "2022-06-19T02:53:39.915999Z",
     "shell.execute_reply": "2022-06-19T02:53:39.915586Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.785176Z"
    },
    "papermill": {
     "duration": 0.032379,
     "end_time": "2022-06-19T02:53:39.916110",
     "exception": false,
     "start_time": "2022-06-19T02:53:39.883731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = Config(model=dict(model_path=\"microsoft/deberta-v3-large\"),\n",
    "                optimizer=dict(name=\"AdamW\", parameters=dict(lr=1e-5, weight_decay=0.01)),\n",
    "                scheduler=dict(name=\"get_cosine_with_hard_restarts_schedule_with_warmup\", \n",
    "                               parameters=dict(num_cycles=2, last_epoch=-1)),\n",
    "                warmup=0.05,\n",
    "                scheduling_after=\"step\",\n",
    "                seed=1,\n",
    "                max_length=75,\n",
    "                batch_size=80,\n",
    "                epochs=6,\n",
    "                num_workers=4,\n",
    "                pin_memory=True,\n",
    "                folds=4,\n",
    "                validation_steps=200, \n",
    "                gradient_accumulation_steps=1,\n",
    "                gradient_norm=1.0,\n",
    "                gradient_scaling=True,\n",
    "                delta=1e-4,\n",
    "                verbose=100,\n",
    "                save_model=False,\n",
    "                device=DEVICE,\n",
    "                input_directory=\"./\",\n",
    "                output_directory=\"./\",\n",
    "                cv_monitor_value=\"pearson\",\n",
    "                amp=True, \n",
    "                debug=True,\n",
    "                decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130138c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:39.965046Z",
     "iopub.status.busy": "2022-06-19T02:53:39.964352Z",
     "iopub.status.idle": "2022-06-19T02:53:39.969699Z",
     "shell.execute_reply": "2022-06-19T02:53:39.969228Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.796421Z"
    },
    "papermill": {
     "duration": 0.031228,
     "end_time": "2022-06-19T02:53:39.969810",
     "exception": false,
     "start_time": "2022-06-19T02:53:39.938582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.seed = seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a193ec1",
   "metadata": {
    "papermill": {
     "duration": 0.024465,
     "end_time": "2022-06-19T02:53:40.017350",
     "exception": false,
     "start_time": "2022-06-19T02:53:39.992885",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74253fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.070237Z",
     "iopub.status.busy": "2022-06-19T02:53:40.069650Z",
     "iopub.status.idle": "2022-06-19T02:53:40.072667Z",
     "shell.execute_reply": "2022-06-19T02:53:40.072194Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.807957Z"
    },
    "papermill": {
     "duration": 0.032908,
     "end_time": "2022-06-19T02:53:40.072788",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.039880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_directory(directory, overwriting=False):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    else:\n",
    "        if overwriting:\n",
    "            shutil.rmtree(directory)\n",
    "            os.mkdir(directory)\n",
    "\n",
    "            \n",
    "def create_folds(data_frame, targets, groups, folds=4, seed=1, shuffle=True, fold_column=\"fold\"):\n",
    "    cv_strategy = StratifiedGroupKFold(n_splits=folds, random_state=seed, shuffle=shuffle)\n",
    "    folds = cv_strategy.split(X=data_frame, y=targets, groups=groups)\n",
    "    for fold, (train_indexes, validation_indexes) in enumerate(folds):\n",
    "        data_frame.loc[validation_indexes, fold_column] =  int(fold+1)\n",
    "        \n",
    "    data_frame[fold_column] = data_frame[fold_column].astype(int)\n",
    "    \n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af67e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.156344Z",
     "iopub.status.busy": "2022-06-19T02:53:40.151159Z",
     "iopub.status.idle": "2022-06-19T02:53:40.186412Z",
     "shell.execute_reply": "2022-06-19T02:53:40.185977Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.821031Z"
    },
    "papermill": {
     "duration": 0.091169,
     "end_time": "2022-06-19T02:53:40.186530",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.095361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_loop(train_loader, \n",
    "                  model,\n",
    "                  optimizer,\n",
    "                  scheduler=None,\n",
    "                  scheduling_after=\"step\",\n",
    "                  epochs=1,\n",
    "                  validation_loader=None, \n",
    "                  gradient_accumulation_steps=1, \n",
    "                  gradient_scaling=False,\n",
    "                  gradient_norm=1,\n",
    "                  validation_steps=\"epoch\", \n",
    "                  amp=False,\n",
    "                  recalculate_metrics_at_end=True, \n",
    "                  return_validation_outputs=True,\n",
    "                  debug=True, \n",
    "                  teacher_model=None,\n",
    "                  pseudo_loader=None,\n",
    "                  verbose=100, \n",
    "                  device=\"cpu\", \n",
    "                  time_format=\"{hours}:{minutes}:{seconds}\", \n",
    "                  logger=[\"print\", \"wandb\"], \n",
    "                  decimals=4):\n",
    "    \n",
    "    training_steps = len(train_loader) * epochs\n",
    "    \n",
    "    if isinstance(validation_steps, float):\n",
    "        validation_steps = int(training_steps * validation_steps)\n",
    "    elif validation_steps == \"epoch\":\n",
    "        validation_steps = len(train_loader)\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        print(f\"Auto Mixed Precision: {amp}\")\n",
    "        print(f\"Gradient norm: {gradient_norm}\")\n",
    "        print(f\"Gradient scaling: {gradient_scaling}\")\n",
    "        print(f\"Gradient accumulation steps: {gradient_accumulation_steps}\")\n",
    "        print(f\"Validation steps: {validation_steps}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print()\n",
    "        \n",
    "    if wandb_run_exists() and \"wandb\" in logger:\n",
    "        print(f\"Weights & Biases Run: {wandb.run.get_url()}\", end=\"\\n\"*2)\n",
    "        \n",
    "    passed_steps = 1\n",
    "    train_loss, train_metrics = Averager(), Averager()\n",
    "    scaler = GradScaler() if gradient_scaling else None\n",
    "    best_validation_loss, best_validation_metrics, best_validation_outputs = None, None, None\n",
    "    total_time = timedelta(seconds=0)\n",
    "    \n",
    "    if device is not None: \n",
    "        model.to(device)\n",
    "        \n",
    "        if teacher_model is not None: teacher_model.to(device)\n",
    "    \n",
    "    for epoch in range(1, epochs+1):\n",
    "        if \"tqdm\" in logger:\n",
    "            bar_format = \"{l_bar} {bar} {n_fmt}/{total_fmt} - remain: {remaining}{postfix}\"\n",
    "            train_loader = tqdm(iterable=train_loader, \n",
    "                                total=len(train_loader),\n",
    "                                colour=\"#000\",\n",
    "                                bar_format=bar_format)\n",
    "            \n",
    "            train_loader.set_description_str(f\"Epoch {epoch}/{epochs}\")\n",
    "        \n",
    "        if \"print\" in logger:\n",
    "            print(f\"\\nEpoch {epoch}/{epochs}\", end=\"\\n\"*2)\n",
    "            \n",
    "        epoch_train_loss, epoch_train_metrics = Averager(), Averager()\n",
    "        timer = Timer(time_format)\n",
    "        steps = len(train_loader)    \n",
    "        \n",
    "        model.zero_grad()\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            batch_size = train_loader.batch_size\n",
    "            \n",
    "            step_timer =  Timer(time_format)\n",
    "            pseudo_batch = next(iter(pseudo_loader)) if pseudo_loader is not None else None\n",
    "            batch_loss, batch_metrics = training_step(batch=batch, \n",
    "                                                      model=model, \n",
    "                                                      optimizer=optimizer,\n",
    "                                                      gradient_norm=gradient_norm,\n",
    "                                                      gradient_accumulation_steps=gradient_accumulation_steps, \n",
    "                                                      amp=amp, \n",
    "                                                      scaler=scaler, \n",
    "                                                      device=device, \n",
    "                                                      overall_loss=epoch_train_loss.average, \n",
    "                                                      overall_metrics=epoch_train_metrics.average,\n",
    "                                                      step=passed_steps, \n",
    "                                                      epoch=epoch, \n",
    "                                                      teacher_model=teacher_model,\n",
    "                                                      pseudo_batch=pseudo_batch)\n",
    "            \n",
    "            lr_key = \"lr\"\n",
    "            lr = get_lr(optimizer, only_last=True, key=lr_key)\n",
    "            \n",
    "            if step % gradient_accumulation_steps == 0:\n",
    "                optimization_step(model=model, optimizer=optimizer, scaler=scaler)\n",
    "    \n",
    "                if scheduling_after == \"step\":\n",
    "                    scheduling_step(scheduler, loop=\"training\")\n",
    "            \n",
    "            elapsed, remain = step_timer(1/1)\n",
    "            step_seconds = step_timer.elapsed_time.total_seconds()\n",
    "            sample_seconds = step_seconds / batch_size\n",
    "            \n",
    "            if wandb_run_exists() and \"wandb\" in logger:\n",
    "                logs = {\"train/seconds vs step\": step_seconds, \n",
    "                        \"train/seconds vs sample\": sample_seconds}\n",
    "                \n",
    "                wandb.log(logs, step=passed_steps)\n",
    "            \n",
    "            train_loss.update(batch_loss, n=batch_size)\n",
    "            epoch_train_loss.update(batch_loss, n=batch_size)\n",
    "            train_metrics.update(batch_metrics, n=batch_size)\n",
    "            epoch_train_metrics.update(batch_metrics, n=batch_size)\n",
    "            \n",
    "            \n",
    "            logs = {\"train/loss\": train_loss.average, \n",
    "                    \"train/loss vs batch\": batch_loss, \n",
    "                    \"train/loss vs epoch\": epoch_train_loss.average,\n",
    "                    \"lr\": lr}\n",
    "            \n",
    "            for metric in batch_metrics:\n",
    "                logs.update({f\"train/{metric}\": train_metrics.average[metric], \n",
    "                             f\"train/{metric} vs batch\": batch_metrics[metric], \n",
    "                             f\"train/{metric} vs epoch\": epoch_train_metrics.average[metric]})\n",
    "                \n",
    "            if wandb_run_exists() and \"wandb\" in logger:\n",
    "                wandb.log(logs, step=passed_steps) \n",
    "            \n",
    "            if \"tqdm\" in logger:\n",
    "                train_loader.set_postfix_str(f\"loss: {epoch_train_loss.average:.{decimals}}\"\n",
    "                                             f\"{format_metrics(epoch_train_metrics.average, decimals=decimals)}\")\n",
    "            if \"print\" in logger:\n",
    "                 if step % verbose == 0 or step == steps and verbose > 0:\n",
    "                    elapsed, remain = timer(step/steps)\n",
    "                    print(f\"{step}/{steps} - \"\n",
    "                          f\"remain: {remain} - \"\n",
    "                          f\"loss: {epoch_train_loss.average:.{decimals}}\"\n",
    "                          f\"{format_metrics(epoch_train_metrics.average, decimals=decimals)} - \"\n",
    "                          f\"lr: {lr}\")\n",
    "                    \n",
    "            \n",
    "            if validation_loader is not None:\n",
    "                if (passed_steps % validation_steps) == 0:\n",
    "                    if step > validation_steps: print()\n",
    "                    validation_loop_steps = len(validation_loader)\n",
    "                    validation_batch_size = validation_loader.batch_size\n",
    "                    \n",
    "                    validation_timer =  Timer(time_format)\n",
    "                    validation_loss, validation_metrics, validation_outputs = validation_loop(loader=validation_loader, \n",
    "                                                                                              model=model,\n",
    "                                                                                              gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                                                                                              amp=amp, \n",
    "                                                                                              return_outputs=True, \n",
    "                                                                                              verbose=verbose, \n",
    "                                                                                              recalculate_metrics_at_end=True, \n",
    "                                                                                              device=device, \n",
    "                                                                                              logger=logger)\n",
    "                    \n",
    "                    \n",
    "                    elapsed, remain = validation_timer(1/1)\n",
    "                    validation_seconds = validation_timer.elapsed_time.total_seconds()\n",
    "                    validation_step_seconds = validation_seconds / validation_loop_steps\n",
    "                    validation_sample_seconds = validation_step_seconds / validation_batch_size\n",
    "            \n",
    "                    if wandb_run_exists() and \"wandb\" in logger:\n",
    "                        logs = {\"validation/seconds vs step\": validation_step_seconds, \n",
    "                                \"validation/seconds vs sample\": validation_sample_seconds}\n",
    "                \n",
    "                        wandb.log(logs, step=passed_steps)\n",
    "                    \n",
    "                    \n",
    "                    logs = {\"validation/loss\": validation_loss, \n",
    "                            \"train/loss vs validation steps\": epoch_train_loss.average}\n",
    "    \n",
    "                    for metric, value in validation_metrics.items():\n",
    "                        logs.update({f\"validation/{metric}\": value, \n",
    "                                     f\"train/{metric} vs validation steps\": epoch_train_metrics.average[metric]})\n",
    "                    \n",
    "                    if wandb_run_exists() and \"wandb\" in logger:\n",
    "                        wandb.log(logs, step=passed_steps)\n",
    "                    \n",
    "                    is_checkpoint_saved = model_checkpointing(loss=validation_loss, \n",
    "                                                              metrics=validation_metrics,\n",
    "                                                              model=model, \n",
    "                                                              optimizer=optimizer, \n",
    "                                                              scheduler=scheduler, \n",
    "                                                              step=passed_steps, \n",
    "                                                              best_loss=best_validation_loss, \n",
    "                                                              best_metrics=validation_metrics)\n",
    "                    \n",
    "                    if is_checkpoint_saved:\n",
    "                        best_validation_loss = validation_loss\n",
    "                        best_validation_metrics = validation_metrics\n",
    "                        best_validation_outputs = validation_outputs\n",
    "                        \n",
    "                    scheduling_step(scheduler, loss=validation_loss, loop=\"validation\")\n",
    "                    print()\n",
    "            \n",
    "            passed_steps += 1\n",
    "        \n",
    "        if scheduling_after == \"epoch\":\n",
    "            scheduling_step(scheduler, loop=\"training\")\n",
    "        \n",
    "        on_epoch_end(model=model, \n",
    "                     step=passed_steps, \n",
    "                     epoch=epoch)\n",
    "        \n",
    "        if \"tqdm\" in logger and \"print\" not in logger:\n",
    "            elapsed, remain = timer(1/1)\n",
    "        \n",
    "        epoch_elapsed_seconds = timer.elapsed_time.total_seconds()\n",
    "        total_time += timedelta(seconds=epoch_elapsed_seconds)\n",
    "        \n",
    "        if wandb_run_exists() and \"wandb\" in logger:\n",
    "            wandb.log({\"epoch\": epoch}, step=passed_steps)\n",
    "        \n",
    "        if \"tqdm\" in logger: train_loader.close()\n",
    "            \n",
    "        print(f\"\\nTraining loss: {epoch_train_loss.average:.{decimals}}\"\n",
    "              f\"{format_metrics(epoch_train_metrics.average, decimals=decimals)}\")\n",
    "        \n",
    "        if validation_loader is not None:\n",
    "            print(f\"Validation loss: {best_validation_loss:.{decimals}}\"\n",
    "                  f\"{format_metrics(best_validation_metrics, decimals=decimals)}\")\n",
    "        \n",
    "        total_time_string = Timer.format_time(total_time, time_format=time_format)\n",
    "        print(f\"Total time: {total_time_string}\")\n",
    "    \n",
    "    if validation_loader is not None:\n",
    "        if return_validation_outputs:\n",
    "            return (epoch_train_loss.average, epoch_train_metrics.average), (best_validation_loss, best_validation_metrics, best_validation_outputs)\n",
    "        \n",
    "        return (epoch_train_loss.average, epoch_train_metrics.average), (best_validation_loss, best_validation_metrics)\n",
    "\n",
    "    return (epoch_train_loss.average, epoch_train_metrics.average)\n",
    "        \n",
    "def validation_loop(loader, \n",
    "                    model, \n",
    "                    gradient_accumulation_steps=1,\n",
    "                    amp=False, \n",
    "                    return_outputs=True, \n",
    "                    recalculate_metrics_at_end=True, \n",
    "                    verbose=1, \n",
    "                    device=\"cpu\", \n",
    "                    time_format=\"{hours}:{minutes}:{seconds}\",\n",
    "                    logger=[\"print\"], \n",
    "                    decimals=4):\n",
    "    \n",
    "    model.eval()\n",
    "    loss, metrics = Averager(), Averager()\n",
    "    timer = Timer(time_format)\n",
    "    outputs, targets = [], []\n",
    "    steps = len(loader)\n",
    "    \n",
    "    if \"tqdm\" in logger:\n",
    "        bar_format = \"{l_bar} {bar} {n_fmt}/{total_fmt} - remain: {remaining}{postfix}\"\n",
    "        loader = tqdm(iterable=loader, \n",
    "                      total=len(loader),\n",
    "                      colour=\"#000\",\n",
    "                      bar_format=bar_format)\n",
    "            \n",
    "        loader.set_description_str(\"[Validation]\")\n",
    "    \n",
    "    is_targets = False\n",
    "    for step, batch in enumerate(loader, 1):\n",
    "        with torch.no_grad():\n",
    "            with autocast(enabled=amp):\n",
    "                batch_loss, batch_outputs = calculate_loss(batch=batch, model=model, return_outputs=True, device=device)\n",
    "                \n",
    "                batch_loss /= gradient_accumulation_steps\n",
    "                loss.update(batch_loss.item(), n=len(batch))\n",
    "                \n",
    "                batch_targets = get_targets(batch)\n",
    "                batch_metrics = calculate_metrics(predictions=batch_outputs, targets=batch_targets, device=device)\n",
    "                metrics.update(batch_metrics, n=len(batch))\n",
    "                \n",
    "                if batch_targets is not None:\n",
    "                    if isinstance(batch_targets, dict):\n",
    "                        targets.append(batch_targets)\n",
    "                    else:\n",
    "                        targets.extend(batch_targets.to(\"cpu\").tolist())\n",
    "                        \n",
    "                    is_targets = True\n",
    "                \n",
    "                outputs.extend(batch_outputs.to(\"cpu\").tolist())\n",
    "                \n",
    "                if step == steps and recalculate_metrics_at_end and is_targets:\n",
    "                    outputs = torch.tensor(outputs)\n",
    "                    targets = torch.tensor(targets)\n",
    "                        \n",
    "                    metrics = Averager(calculate_metrics(predictions=outputs, targets=targets))\n",
    "                \n",
    "                if \"tqdm\" in logger:\n",
    "                    loader.set_postfix_str(f\"loss: {loss.average:.{decimals}}\"\n",
    "                                           f\"{format_metrics(metrics.average, decimals=decimals)}\")\n",
    "                \n",
    "                if \"print\" in logger:\n",
    "                    if step % verbose == 0 or step == steps and verbose > 0:\n",
    "                        elapsed, remain = timer(step/steps)\n",
    "\n",
    "                        print(f\"[Validation] \"\n",
    "                              f\"{step}/{steps} - \"\n",
    "                              f\"remain: {remain} - \"\n",
    "                              f\"loss: {loss.average:.{decimals}}\"\n",
    "                              f\"{format_metrics(metrics.average, decimals=decimals)}\")\n",
    "                    \n",
    "    if not recalculate_metrics_at_end: \n",
    "        outputs = torch.tensor(outputs)\n",
    "        \n",
    "    if \"tqdm\" in logger:\n",
    "        loader.close()\n",
    "        \n",
    "    return (loss.average, metrics.average, outputs) if return_outputs else (loss.average, metrics.average)\n",
    "\n",
    "\n",
    "def format_metrics(metrics, sep=\" - \", add_sep_to_start=True, decimals=4):\n",
    "    if metrics != {}:\n",
    "        string = sep.join([f\"{k}: {v:.{decimals}}\" for k, v in metrics.items()])\n",
    "        return sep + string if add_sep_to_start else string \n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "    \n",
    "def training_step(batch, \n",
    "                  model, \n",
    "                  optimizer, \n",
    "                  gradient_norm=1.0, \n",
    "                  amp=False, \n",
    "                  gradient_accumulation_steps=1, \n",
    "                  scaler=None, \n",
    "                  device=\"cpu\", \n",
    "                  overall_loss=None, \n",
    "                  overall_metrics=None, \n",
    "                  step=None, \n",
    "                  epoch=None,\n",
    "                  teacher_model=None,\n",
    "                  pseudo_batch=None):\n",
    "    \n",
    "    model.train()\n",
    "    with autocast(enabled=amp):\n",
    "        loss, outputs = calculate_loss(batch=batch, model=model, return_outputs=True, device=device)\n",
    "        targets = get_targets(batch)\n",
    "        metrics = calculate_metrics(predictions=outputs, targets=targets, device=device)\n",
    "        \n",
    "        loss /= gradient_accumulation_steps\n",
    "        loss = backward_step(loss=loss, optimizer=optimizer, scaler=scaler)\n",
    "        \n",
    "        adversarial_loss = adversarial_step(batch=batch, \n",
    "                                            model=model, \n",
    "                                            device=device, \n",
    "                                            loss=overall_loss, \n",
    "                                            metrics=overall_metrics, \n",
    "                                            step=step, \n",
    "                                            epoch=epoch)\n",
    "        \n",
    "        if adversarial_loss is not None:\n",
    "            adversarial_loss = backward_step(loss=adversarial_loss, optimizer=optimizer, scaler=scaler)\n",
    "        \n",
    "        if pseudo_batch is not None and teacher_model is not None:\n",
    "            pseudo_loss = pseudo_labeling_step(batch=batch,\n",
    "                                               pseudo_batch=pseudo_batch,\n",
    "                                               model=model, \n",
    "                                               teacher_model=teacher_model, \n",
    "                                               loss=loss, \n",
    "                                               metrics=metrics,\n",
    "                                               step=step, \n",
    "                                               epoch=epoch, \n",
    "                                               device=device)\n",
    "        \n",
    "            if pseudo_loss is not None:\n",
    "                pseudo_loss = backward_step(loss=pseudo_loss, optimizer=optimizer, scaler=scaler)\n",
    "            \n",
    "    if gradient_norm > 0:\n",
    "        if scaler is not None:\n",
    "            scaler.unscale_(optimizer)\n",
    "                            \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_norm)\n",
    "        \n",
    "    return loss.detach(), metrics\n",
    "\n",
    "def backward_step(loss, optimizer, scaler=None):\n",
    "    if scaler is not None:\n",
    "        scaler.scale(loss).backward()\n",
    "    else:\n",
    "        loss.backward()\n",
    "        \n",
    "    return loss\n",
    "        \n",
    "\n",
    "def optimization_step(model, optimizer, scaler=None):                        \n",
    "    if scaler is not None:\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    else:\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.zero_grad()\n",
    "        \n",
    "\n",
    "def scheduling_step(scheduler=None, loss=None, loop=\"training\"):\n",
    "    if scheduler is not None:\n",
    "        if loop == \"validation\":\n",
    "            if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(loss)\n",
    "        else:\n",
    "            if not isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step()\n",
    "\n",
    "                \n",
    "def adversarial_step(batch, \n",
    "                     model, \n",
    "                     device=\"cpu\", \n",
    "                     loss=None, \n",
    "                     metrics=None, \n",
    "                     step=None, \n",
    "                     epoch=None):\n",
    "    pass\n",
    "\n",
    "                \n",
    "    \n",
    "def calculate_loss(batch, model, return_outputs=True, device=\"cpu\"):\n",
    "    raise NotImplementedError(f\"`calculate_loss` function is not implemented.\")\n",
    "                \n",
    "def calculate_metrics(predictions, targets, device=\"cpu\"):\n",
    "    return dict()\n",
    "\n",
    "def get_targets(batch):\n",
    "    return []\n",
    "\n",
    "\n",
    "def on_epoch_end(model=None, step=None, epoch=None):\n",
    "    pass\n",
    "\n",
    "\n",
    "def model_checkpointing(loss, \n",
    "                        metrics, \n",
    "                        model, \n",
    "                        optimizer=None, \n",
    "                        scheduler=None, \n",
    "                        step=None, \n",
    "                        best_loss=None, \n",
    "                        best_metrics=None):\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "def pseudo_labeling_step(batch, \n",
    "                         pseudo_batch, \n",
    "                         model, \n",
    "                         teacher_model, \n",
    "                         loss=None, \n",
    "                         metrics=None, \n",
    "                         step=None, \n",
    "                         epoch=None, \n",
    "                         device=\"cpu\"):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373396e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.241204Z",
     "iopub.status.busy": "2022-06-19T02:53:40.240413Z",
     "iopub.status.idle": "2022-06-19T02:53:40.242152Z",
     "shell.execute_reply": "2022-06-19T02:53:40.242607Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.892473Z"
    },
    "papermill": {
     "duration": 0.033606,
     "end_time": "2022-06-19T02:53:40.242730",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.209124",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_loss(batch, model, return_outputs=True, device=\"cpu\"):\n",
    "    input_ids, attention_mask, targets = batch\n",
    "    \n",
    "    input_ids = input_ids.to(device).long()\n",
    "    attention_mask = attention_mask.to(device).long()\n",
    "    targets = targets.to(device).float()\n",
    "    \n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    outputs = outputs.sigmoid().squeeze(dim=-1)\n",
    "    loss = F.mse_loss(outputs, targets, reduction=\"mean\")\n",
    "    \n",
    "    return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "def calculate_metrics(predictions, targets, device=\"cpu\"):\n",
    "    predictions = predictions.sigmoid().detach().view(-1).to(\"cpu\").float().numpy()\n",
    "    targets = targets.view(-1).to(\"cpu\").float().numpy()\n",
    "    \n",
    "    return dict(pearson=scipy.stats.pearsonr(predictions, targets)[0])\n",
    "\n",
    "\n",
    "def get_targets(batch):\n",
    "    *_, targets = batch\n",
    "    return targets\n",
    "\n",
    "\n",
    "def model_checkpointing(loss, \n",
    "                        metrics, \n",
    "                        model, \n",
    "                        optimizer=None, \n",
    "                        scheduler=None, \n",
    "                        step=None, \n",
    "                        best_loss=None, \n",
    "                        best_metrics=None):\n",
    "    \n",
    "    is_saved_checkpoint = model_checkpoint(value=metrics[\"pearson\"], \n",
    "                                           model=model, \n",
    "                                           optimizer=optimizer, \n",
    "                                           scheduler=scheduler, \n",
    "                                           step=step)\n",
    "    return is_saved_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad9e5a",
   "metadata": {
    "papermill": {
     "duration": 0.021565,
     "end_time": "2022-06-19T02:53:40.286770",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.265205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd517377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.341779Z",
     "iopub.status.busy": "2022-06-19T02:53:40.340668Z",
     "iopub.status.idle": "2022-06-19T02:53:40.343380Z",
     "shell.execute_reply": "2022-06-19T02:53:40.342911Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.907943Z"
    },
    "papermill": {
     "duration": 0.034879,
     "end_time": "2022-06-19T02:53:40.343484",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.308605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DynamicPadding:\n",
    "    def __init__(self, tokenizer, max_length=None, padding=True, pad_to_multiple_of=None, return_tensors=\"pt\"):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.padding = padding\n",
    "        self.pad_to_multiple_of = pad_to_multiple_of\n",
    "        self.return_tensors = return_tensors\n",
    "    \n",
    "    def __call__(self, tokenized):\n",
    "        max_length = max(len(_[\"input_ids\"]) for _ in tokenized)\n",
    "        max_length = min(max_length, self.max_length) if self.max_length is not None else max_length\n",
    "                \n",
    "        padded = self.tokenizer.pad(encoded_inputs=tokenized,\n",
    "                                    max_length=max_length,\n",
    "                                    padding=self.padding, \n",
    "                                    pad_to_multiple_of=self.pad_to_multiple_of, \n",
    "                                    return_tensors=self.return_tensors)\n",
    "        \n",
    "        return padded\n",
    "    \n",
    "    \n",
    "    \n",
    "class Collator:\n",
    "    def __init__(self, return_targets=True, **kwargs):\n",
    "        self.dynamic_padding = DynamicPadding(**kwargs)\n",
    "        self.return_targets = return_targets\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        all_tokenized, all_targets = [], []\n",
    "        for sample in batch:\n",
    "            if self.return_targets:\n",
    "                tokenized, target = sample\n",
    "                all_targets.append(target)\n",
    "            else:\n",
    "                tokenized = sample\n",
    "                \n",
    "            all_tokenized.append(tokenized)\n",
    "        \n",
    "        tokenized = self.dynamic_padding(all_tokenized)\n",
    "        \n",
    "        input_ids = torch.tensor(tokenized.input_ids)\n",
    "        attention_mask = torch.tensor(tokenized.attention_mask)\n",
    "        \n",
    "        if self.return_targets:\n",
    "            all_targets = torch.tensor(all_targets)\n",
    "        \n",
    "            return input_ids, attention_mask, all_targets\n",
    "        \n",
    "        return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3d8132c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.396486Z",
     "iopub.status.busy": "2022-06-19T02:53:40.391098Z",
     "iopub.status.idle": "2022-06-19T02:53:40.398733Z",
     "shell.execute_reply": "2022-06-19T02:53:40.398269Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.922498Z"
    },
    "papermill": {
     "duration": 0.033528,
     "end_time": "2022-06-19T02:53:40.398837",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.365309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, texts, pair_texts, tokenizer, contexts=None, sep=None, targets=None, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.pair_texts = pair_texts\n",
    "        self.contexts = contexts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.sep = sep if sep is not None else self.tokenizer.sep_token\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.texts[index].lower()\n",
    "        pair_text = self.pair_texts[index].lower()\n",
    "        \n",
    "        if self.contexts is not None:\n",
    "            context = self.contexts[index].lower()\n",
    "            text = text + self.sep + context\n",
    "    \n",
    "        \n",
    "        tokenized = self.tokenizer(text=text, \n",
    "                                   text_pair=pair_text, \n",
    "                                   add_special_tokens=True,\n",
    "                                   #max_length=self.max_length,\n",
    "                                   #padding=\"max_length\",\n",
    "                                   #truncation=True,\n",
    "                                   return_attention_mask=True,\n",
    "                                   return_token_type_ids=False,\n",
    "                                   return_offsets_mapping=False)\n",
    "        \n",
    "        \n",
    "        if self.targets is not None:\n",
    "            target = self.targets[index]\n",
    "            \n",
    "            return tokenized, target\n",
    "            \n",
    "        return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74dac19",
   "metadata": {
    "papermill": {
     "duration": 0.021748,
     "end_time": "2022-06-19T02:53:40.442845",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.421097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c7f014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.499593Z",
     "iopub.status.busy": "2022-06-19T02:53:40.498837Z",
     "iopub.status.idle": "2022-06-19T02:53:40.504798Z",
     "shell.execute_reply": "2022-06-19T02:53:40.504391Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.937071Z"
    },
    "papermill": {
     "duration": 0.040393,
     "end_time": "2022-06-19T02:53:40.504900",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.464507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, model_path=\"microsoft/deberta-v3-large\", config_path=None, config_updates={}, reinitialization_layers=0, mixout=0.0):\n",
    "        super(Model, self).__init__()\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(model_path)\n",
    "        else:\n",
    "            self.config = AutoConfig.from_pretrained(config_path)\n",
    "        \n",
    "        self.config.output_hidden_states = True\n",
    "        self.config.update(config_updates)\n",
    "        \n",
    "        if config_path is None:\n",
    "            self.model = AutoModel.from_pretrained(model_path, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel.from_config(self.config)\n",
    "        \n",
    "        self.model.gradient_checkpointing_enable()\n",
    "        print(f\"Gradient Checkpointing: {self.model.is_gradient_checkpointing}\")\n",
    "        \n",
    "        if mixout > 0:\n",
    "            for module in self.model.modules():\n",
    "                for name, submodule in module.named_children():\n",
    "                    if isinstance(submodule, nn.Dropout):\n",
    "                        module.p = 0.0\n",
    "                    if isinstance(submodule, nn.Linear):\n",
    "                        target_state_dict = submodule.state_dict()\n",
    "                        bias = True if submodule.bias is not None else False\n",
    "                        \n",
    "                        new_module = MixLinear(in_features=submodule.in_features, \n",
    "                                               out_features=submodule.out_features, \n",
    "                                               bias=bias, \n",
    "                                               target=target_state_dict[\"weight\"], \n",
    "                                               p=mixout)\n",
    "                        \n",
    "                        new_module.load_state_dict(target_state_dict)\n",
    "                        setattr(module, name, new_module)\n",
    "                \n",
    "            print(f\"Initialized Mixout (p={mixout}) Regularization\")\n",
    "        \n",
    "        if reinitialization_layers > 0:\n",
    "            layers = ...\n",
    "            for layer in layers[-reinitialization_layers:]:\n",
    "                for name, module in layer.named_modules():\n",
    "                    self.init_weights(module, std=self.config.initializer_range)\n",
    "            \n",
    "            print(f\"Reinitializated last {n} layers.\")\n",
    "\n",
    "        self.head = nn.Linear(in_features=self.config.hidden_size, out_features=1)\n",
    "        self.init_weights(self.head, std=self.config.initializer_range)\n",
    "            \n",
    "    \n",
    "    def init_weights(self, module, std=0.02):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=std)\n",
    "            if module.padding_idx is not None:\n",
    "                 module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "    \n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        transformer_outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        features = transformer_outputs.hidden_states[-1]\n",
    "        features = features[:, 0, :]\n",
    "        outputs = self.head(features)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f22071",
   "metadata": {
    "papermill": {
     "duration": 0.021556,
     "end_time": "2022-06-19T02:53:40.548665",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.527109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee82128",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.596513Z",
     "iopub.status.busy": "2022-06-19T02:53:40.595763Z",
     "iopub.status.idle": "2022-06-19T02:53:40.598009Z",
     "shell.execute_reply": "2022-06-19T02:53:40.598403Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.958523Z"
    },
    "papermill": {
     "duration": 0.028022,
     "end_time": "2022-06-19T02:53:40.598526",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.570504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_path = \"../input/us-patent-phrase-to-phrase-matching/train.csv\"\n",
    "test_path = \"../input/us-patent-phrase-to-phrase-matching/test.csv\"\n",
    "sample_submission_path = \"../input/us-patent-phrase-to-phrase-matching/sample_submission.csv\"\n",
    "cpc_codes_path = \"../input/cpc-codes/titles.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c027fd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:40.647823Z",
     "iopub.status.busy": "2022-06-19T02:53:40.647199Z",
     "iopub.status.idle": "2022-06-19T02:53:41.521445Z",
     "shell.execute_reply": "2022-06-19T02:53:41.521850Z",
     "shell.execute_reply.started": "2022-06-19T01:55:20.969229Z"
    },
    "papermill": {
     "duration": 0.901277,
     "end_time": "2022-06-19T02:53:41.521991",
     "exception": false,
     "start_time": "2022-06-19T02:53:40.620714",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>718f1c6953e3942f</td>\n",
       "      <td>undulation</td>\n",
       "      <td>undulatory swimmers</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>4dc407e6d0aa7844</td>\n",
       "      <td>undulation</td>\n",
       "      <td>voltage fluctuate</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>de69548ad79caccc</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer from web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>6620317413e6e03f</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer to web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>96946de83b530746</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score  \\\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
       "...                 ...           ...                     ...     ...    ...   \n",
       "36468  718f1c6953e3942f    undulation     undulatory swimmers     B31   0.00   \n",
       "36469  4dc407e6d0aa7844    undulation       voltage fluctuate     B31   0.00   \n",
       "36470  de69548ad79caccc  web transfer       transfer from web     B31   0.75   \n",
       "36471  6620317413e6e03f  web transfer         transfer to web     B31   0.25   \n",
       "36472  96946de83b530746  web transfer            transfer web     B31   0.75   \n",
       "\n",
       "      code                                              title section  class  \\\n",
       "0      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "1      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "2      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "3      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "4      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "...    ...                                                ...     ...    ...   \n",
       "36468  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36469  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36470  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36471  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36472  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "\n",
       "      subclass  group  main_group  \n",
       "0          NaN    NaN         NaN  \n",
       "1          NaN    NaN         NaN  \n",
       "2          NaN    NaN         NaN  \n",
       "3          NaN    NaN         NaN  \n",
       "4          NaN    NaN         NaN  \n",
       "...        ...    ...         ...  \n",
       "36468      NaN    NaN         NaN  \n",
       "36469      NaN    NaN         NaN  \n",
       "36470      NaN    NaN         NaN  \n",
       "36471      NaN    NaN         NaN  \n",
       "36472      NaN    NaN         NaN  \n",
       "\n",
       "[36473 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpc_codes = pd.read_csv(cpc_codes_path)\n",
    "train = pd.read_csv(train_path)\n",
    "train = train.merge(cpc_codes, left_on=\"context\", right_on=\"code\")\n",
    "\n",
    "if DEBUG:\n",
    "    display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b6d94a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:41.572550Z",
     "iopub.status.busy": "2022-06-19T02:53:41.572008Z",
     "iopub.status.idle": "2022-06-19T02:53:41.620982Z",
     "shell.execute_reply": "2022-06-19T02:53:41.620552Z",
     "shell.execute_reply.started": "2022-06-19T01:55:21.613752Z"
    },
    "papermill": {
     "duration": 0.075843,
     "end_time": "2022-06-19T02:53:41.621098",
     "exception": false,
     "start_time": "2022-06-19T02:53:41.545255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cpc_texts = torch.load(\"../input/foldsdump/cpc_texts.pth\")\n",
    "train['context_text'] = train['context'].map(cpc_texts)\n",
    "train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n",
    "train['text'] = train['text'].apply(str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e0d8119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:41.672130Z",
     "iopub.status.busy": "2022-06-19T02:53:41.671343Z",
     "iopub.status.idle": "2022-06-19T02:53:41.690363Z",
     "shell.execute_reply": "2022-06-19T02:53:41.690780Z",
     "shell.execute_reply.started": "2022-06-19T01:55:21.653538Z"
    },
    "papermill": {
     "duration": 0.046272,
     "end_time": "2022-06-19T02:53:41.690903",
     "exception": false,
     "start_time": "2022-06-19T02:53:41.644631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>anchor</th>\n",
       "      <th>target</th>\n",
       "      <th>context</th>\n",
       "      <th>score</th>\n",
       "      <th>code</th>\n",
       "      <th>title</th>\n",
       "      <th>section</th>\n",
       "      <th>class</th>\n",
       "      <th>subclass</th>\n",
       "      <th>group</th>\n",
       "      <th>main_group</th>\n",
       "      <th>context_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37d61fd2272659b1</td>\n",
       "      <td>abatement</td>\n",
       "      <td>abatement of pollution</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]abatement of pollution[sep]human...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7b9652b17b68b7a4</td>\n",
       "      <td>abatement</td>\n",
       "      <td>act of abating</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.75</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]act of abating[sep]human necessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36d72442aefd8232</td>\n",
       "      <td>abatement</td>\n",
       "      <td>active catalyst</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.25</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]active catalyst[sep]human necess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5296b0c19e1ce60e</td>\n",
       "      <td>abatement</td>\n",
       "      <td>eliminating process</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]eliminating process[sep]human ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54c1e3b9184cb5b6</td>\n",
       "      <td>abatement</td>\n",
       "      <td>forest region</td>\n",
       "      <td>A47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>A47</td>\n",
       "      <td>FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...</td>\n",
       "      <td>A</td>\n",
       "      <td>47.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n",
       "      <td>abatement[sep]forest region[sep]human necessit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36468</th>\n",
       "      <td>718f1c6953e3942f</td>\n",
       "      <td>undulation</td>\n",
       "      <td>undulatory swimmers</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>undulation[sep]undulatory swimmers[sep]perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36469</th>\n",
       "      <td>4dc407e6d0aa7844</td>\n",
       "      <td>undulation</td>\n",
       "      <td>voltage fluctuate</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>undulation[sep]voltage fluctuate[sep]performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36470</th>\n",
       "      <td>de69548ad79caccc</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer from web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>web transfer[sep]transfer from web[sep]perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36471</th>\n",
       "      <td>6620317413e6e03f</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer to web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>web transfer[sep]transfer to web[sep]performin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36472</th>\n",
       "      <td>96946de83b530746</td>\n",
       "      <td>web transfer</td>\n",
       "      <td>transfer web</td>\n",
       "      <td>B31</td>\n",
       "      <td>0.75</td>\n",
       "      <td>B31</td>\n",
       "      <td>MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...</td>\n",
       "      <td>B</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...</td>\n",
       "      <td>web transfer[sep]transfer web[sep]performing o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36473 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id        anchor                  target context  score  \\\n",
       "0      37d61fd2272659b1     abatement  abatement of pollution     A47   0.50   \n",
       "1      7b9652b17b68b7a4     abatement          act of abating     A47   0.75   \n",
       "2      36d72442aefd8232     abatement         active catalyst     A47   0.25   \n",
       "3      5296b0c19e1ce60e     abatement     eliminating process     A47   0.50   \n",
       "4      54c1e3b9184cb5b6     abatement           forest region     A47   0.00   \n",
       "...                 ...           ...                     ...     ...    ...   \n",
       "36468  718f1c6953e3942f    undulation     undulatory swimmers     B31   0.00   \n",
       "36469  4dc407e6d0aa7844    undulation       voltage fluctuate     B31   0.00   \n",
       "36470  de69548ad79caccc  web transfer       transfer from web     B31   0.75   \n",
       "36471  6620317413e6e03f  web transfer         transfer to web     B31   0.25   \n",
       "36472  96946de83b530746  web transfer            transfer web     B31   0.75   \n",
       "\n",
       "      code                                              title section  class  \\\n",
       "0      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "1      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "2      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "3      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "4      A47  FURNITURE; DOMESTIC ARTICLES OR APPLIANCES; CO...       A   47.0   \n",
       "...    ...                                                ...     ...    ...   \n",
       "36468  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36469  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36470  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36471  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "36472  B31  MAKING ARTICLES OF PAPER, CARDBOARD OR MATERIA...       B   31.0   \n",
       "\n",
       "      subclass  group  main_group  \\\n",
       "0          NaN    NaN         NaN   \n",
       "1          NaN    NaN         NaN   \n",
       "2          NaN    NaN         NaN   \n",
       "3          NaN    NaN         NaN   \n",
       "4          NaN    NaN         NaN   \n",
       "...        ...    ...         ...   \n",
       "36468      NaN    NaN         NaN   \n",
       "36469      NaN    NaN         NaN   \n",
       "36470      NaN    NaN         NaN   \n",
       "36471      NaN    NaN         NaN   \n",
       "36472      NaN    NaN         NaN   \n",
       "\n",
       "                                            context_text  \\\n",
       "0      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "1      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "2      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "3      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "4      HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...   \n",
       "...                                                  ...   \n",
       "36468  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36469  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36470  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36471  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "36472  PERFORMING OPERATIONS; TRANSPORTING. MAKING AR...   \n",
       "\n",
       "                                                    text  \n",
       "0      abatement[sep]abatement of pollution[sep]human...  \n",
       "1      abatement[sep]act of abating[sep]human necessi...  \n",
       "2      abatement[sep]active catalyst[sep]human necess...  \n",
       "3      abatement[sep]eliminating process[sep]human ne...  \n",
       "4      abatement[sep]forest region[sep]human necessit...  \n",
       "...                                                  ...  \n",
       "36468  undulation[sep]undulatory swimmers[sep]perform...  \n",
       "36469  undulation[sep]voltage fluctuate[sep]performin...  \n",
       "36470  web transfer[sep]transfer from web[sep]perform...  \n",
       "36471  web transfer[sep]transfer to web[sep]performin...  \n",
       "36472  web transfer[sep]transfer web[sep]performing o...  \n",
       "\n",
       "[36473 rows x 14 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42adebf3",
   "metadata": {
    "papermill": {
     "duration": 0.023155,
     "end_time": "2022-06-19T02:53:41.737439",
     "exception": false,
     "start_time": "2022-06-19T02:53:41.714284",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e31f092b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:41.791605Z",
     "iopub.status.busy": "2022-06-19T02:53:41.790789Z",
     "iopub.status.idle": "2022-06-19T02:53:54.660441Z",
     "shell.execute_reply": "2022-06-19T02:53:54.659993Z",
     "shell.execute_reply.started": "2022-06-19T01:55:21.681617Z"
    },
    "papermill": {
     "duration": 12.89918,
     "end_time": "2022-06-19T02:53:54.660570",
     "exception": false,
     "start_time": "2022-06-19T02:53:41.761390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "1    9118\n",
       "2    9119\n",
       "3    9118\n",
       "4    9118\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train[\"score_bin\"] = pd.cut(train[\"score\"], bins=4, labels=False)\n",
    "train = create_folds(data_frame=train, \n",
    "                     targets=train[\"score_bin\"].values,\n",
    "                     groups=train[\"text\"].values,\n",
    "                     folds=config.folds, \n",
    "                     seed=config.seed, \n",
    "                     shuffle=True)\n",
    "\n",
    "if DEBUG:\n",
    "    folds_samples_count = train.groupby(\"fold\").size()\n",
    "    display(folds_samples_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57f5c60",
   "metadata": {
    "papermill": {
     "duration": 0.024548,
     "end_time": "2022-06-19T02:53:54.710747",
     "exception": false,
     "start_time": "2022-06-19T02:53:54.686199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41847aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:53:54.764592Z",
     "iopub.status.busy": "2022-06-19T02:53:54.763837Z",
     "iopub.status.idle": "2022-06-19T02:54:01.519446Z",
     "shell.execute_reply": "2022-06-19T02:54:01.519990Z",
     "shell.execute_reply.started": "2022-06-19T01:55:34.233753Z"
    },
    "papermill": {
     "duration": 6.785686,
     "end_time": "2022-06-19T02:54:01.520188",
     "exception": false,
     "start_time": "2022-06-19T02:53:54.734502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da3bd4dcf3b4c8ca994bbbedfa1a542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5da48719f74459a6cc6d7e0c4e4ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/580 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9599ca264843b194063d0477803ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer: PreTrainedTokenizerFast(name_or_path='microsoft/deberta-v3-large', vocab_size=128000, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '[CLS]', 'eos_token': '[SEP]', 'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.model.model_path)\n",
    "tokenizer_path = os.path.join(config.output_directory, \"tokenizer/\")\n",
    "tokenizer_files = tokenizer.save_pretrained(tokenizer_path)\n",
    "\n",
    "if DEBUG:\n",
    "    print(f\"Tokenizer: {tokenizer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50db4a86",
   "metadata": {
    "papermill": {
     "duration": 0.026755,
     "end_time": "2022-06-19T02:54:01.574306",
     "exception": false,
     "start_time": "2022-06-19T02:54:01.547551",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26b85f44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-19T02:54:01.650874Z",
     "iopub.status.busy": "2022-06-19T02:54:01.650184Z",
     "iopub.status.idle": "2022-06-19T12:37:33.522578Z",
     "shell.execute_reply": "2022-06-19T12:37:33.523128Z",
     "shell.execute_reply.started": "2022-06-19T01:55:40.034938Z"
    },
    "papermill": {
     "duration": 35011.923137,
     "end_time": "2022-06-19T12:37:33.523359",
     "exception": false,
     "start_time": "2022-06-19T02:54:01.600222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/4\n",
      "\n",
      "Train samples: 27355\n",
      "Validation samples: 9118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a81c1f0083244a9b2c1e2d281c00b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/833M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 6\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/6\n",
      "\n",
      "100/342 - remain: 0:15:39 - loss: 0.06929 - pearson: 0.1557 - lr: 9.649122807017543e-06\n",
      "200/342 - remain: 0:9:2 - loss: 0.05111 - pearson: 0.4418 - lr: 9.760582915150719e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02582 - pearson: 0.7965\n",
      "'best_value' is improved by inf! New 'best_value': 0.7965305550218793. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:2:54 - loss: 0.04245 - pearson: 0.5577 - lr: 9.031210290080277e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.04023 - pearson: 0.5867 - lr: 8.59513134969601e-06\n",
      "\n",
      "Training loss: 0.04023 - pearson: 0.5867\n",
      "Validation loss: 0.02582 - pearson: 0.7965\n",
      "Total time: 0:23:22\n",
      "\n",
      "Epoch 2/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01975 - pearson: 0.8383\n",
      "'best_value' is improved by 0.041818762663763276! New 'best_value': 0.8383493176856426. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:19:19 - loss: 0.02025 - pearson: 0.8349 - lr: 7.309279104002865e-06\n",
      "200/342 - remain: 0:10:20 - loss: 0.01981 - pearson: 0.8391 - lr: 5.7855943521806924e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01882 - pearson: 0.8475\n",
      "'best_value' is improved by 0.009173502714038495! New 'best_value': 0.8475228203996811. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:7 - loss: 0.01958 - pearson: 0.8411 - lr: 4.1810012886451036e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01953 - pearson: 0.8412 - lr: 3.522814566610285e-06\n",
      "\n",
      "Training loss: 0.01953 - pearson: 0.8412\n",
      "Validation loss: 0.01882 - pearson: 0.8475\n",
      "Total time: 0:48:21\n",
      "\n",
      "Epoch 3/6\n",
      "\n",
      "100/342 - remain: 0:14:42 - loss: 0.01571 - pearson: 0.8711 - lr: 2.0857696856899236e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01821 - pearson: 0.852\n",
      "'best_value' is improved by 0.004446641673391594! New 'best_value': 0.8519694620730727. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/342 - remain: 0:9:54 - loss: 0.01575 - pearson: 0.8723 - lr: 9.488611970697137e-07\n",
      "300/342 - remain: 0:2:51 - loss: 0.01581 - pearson: 0.8732 - lr: 2.2917923273898912e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01849 - pearson: 0.8519\n",
      "\n",
      "342/342 - remain: 0:0:0 - loss: 0.0157 - pearson: 0.8736 - lr: 7.087165113121964e-08\n",
      "\n",
      "Training loss: 0.0157 - pearson: 0.8736\n",
      "Validation loss: 0.01821 - pearson: 0.852\n",
      "Total time: 1:12:36\n",
      "\n",
      "Epoch 4/6\n",
      "\n",
      "100/342 - remain: 0:14:50 - loss: 0.01509 - pearson: 0.8797 - lr: 9.94102350542652e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01962 - pearson: 0.8464\n",
      "\n",
      "200/342 - remain: 0:9:44 - loss: 0.01553 - pearson: 0.8769 - lr: 9.444042969522029e-06\n",
      "300/342 - remain: 0:2:50 - loss: 0.01569 - pearson: 0.8752 - lr: 8.4893707345265e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01571 - pearson: 0.8752 - lr: 7.974146320430544e-06\n",
      "\n",
      "Training loss: 0.01571 - pearson: 0.8752\n",
      "Validation loss: 0.01821 - pearson: 0.852\n",
      "Total time: 1:35:44\n",
      "\n",
      "Epoch 5/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01821 - pearson: 0.8538\n",
      "'best_value' is improved by 0.0018697480019926882! New 'best_value': 0.8538392100750654. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:19:14 - loss: 0.01261 - pearson: 0.8996 - lr: 6.547843559486482e-06\n",
      "200/342 - remain: 0:10:13 - loss: 0.01273 - pearson: 0.8992 - lr: 4.962128490082072e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.0184 - pearson: 0.8542\n",
      "'best_value' is improved by 0.00033448292842808147! New 'best_value': 0.8541736930034934. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:7 - loss: 0.01262 - pearson: 0.8999 - lr: 3.38031380504396e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01256 - pearson: 0.9007 - lr: 2.756724203475174e-06\n",
      "\n",
      "Training loss: 0.01256 - pearson: 0.9007\n",
      "Validation loss: 0.0184 - pearson: 0.8542\n",
      "Total time: 2:0:42\n",
      "\n",
      "Epoch 6/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01767 - pearson: 0.8596\n",
      "'best_value' is improved by 0.005412969696550918! New 'best_value': 0.8595866627000444. Checkpoint path: './fold_1/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:52 - loss: 0.01051 - pearson: 0.9155 - lr: 1.4567824956831044e-06\n",
      "200/342 - remain: 0:10:2 - loss: 0.01067 - pearson: 0.9153 - lr: 5.217565303628785e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01791 - pearson: 0.8589\n",
      "\n",
      "300/342 - remain: 0:3:1 - loss: 0.01048 - pearson: 0.9171 - lr: 4.794457143692644e-08\n",
      "342/342 - remain: 0:0:0 - loss: 0.01052 - pearson: 0.9167 - lr: 2.5971524677537164e-11\n",
      "\n",
      "Training loss: 0.01052 - pearson: 0.9167\n",
      "Validation loss: 0.01767 - pearson: 0.8596\n",
      "Total time: 2:25:8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 2/4\n",
      "\n",
      "Train samples: 27354\n",
      "Validation samples: 9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 6\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/6\n",
      "\n",
      "100/342 - remain: 0:15:58 - loss: 0.05992 - pearson: 0.2515 - lr: 9.649122807017543e-06\n",
      "200/342 - remain: 0:9:6 - loss: 0.04558 - pearson: 0.4913 - lr: 9.760582915150719e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02612 - pearson: 0.7932\n",
      "'best_value' is improved by inf! New 'best_value': 0.7932345195156443. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:2:53 - loss: 0.03884 - pearson: 0.5918 - lr: 9.031210290080277e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.03698 - pearson: 0.618 - lr: 8.59513134969601e-06\n",
      "\n",
      "Training loss: 0.03698 - pearson: 0.618\n",
      "Validation loss: 0.02612 - pearson: 0.7932\n",
      "Total time: 0:23:21\n",
      "\n",
      "Epoch 2/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02145 - pearson: 0.8304\n",
      "'best_value' is improved by 0.037161518581760866! New 'best_value': 0.8303960380974051. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:25 - loss: 0.0196 - pearson: 0.8461 - lr: 7.309279104002865e-06\n",
      "200/342 - remain: 0:10:9 - loss: 0.01878 - pearson: 0.8476 - lr: 5.7855943521806924e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01949 - pearson: 0.8419\n",
      "'best_value' is improved by 0.011525138753108344! New 'best_value': 0.8419211768505135. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:6 - loss: 0.01864 - pearson: 0.8478 - lr: 4.1810012886451036e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.0185 - pearson: 0.8493 - lr: 3.522814566610285e-06\n",
      "\n",
      "Training loss: 0.0185 - pearson: 0.8493\n",
      "Validation loss: 0.01949 - pearson: 0.8419\n",
      "Total time: 0:48:14\n",
      "\n",
      "Epoch 3/6\n",
      "\n",
      "100/342 - remain: 0:15:48 - loss: 0.01444 - pearson: 0.8856 - lr: 2.0857696856899236e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01964 - pearson: 0.8437\n",
      "'best_value' is improved by 0.0017585205819096172! New 'best_value': 0.8436796974324231. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/342 - remain: 0:10:23 - loss: 0.01439 - pearson: 0.8855 - lr: 9.488611970697137e-07\n",
      "300/342 - remain: 0:2:55 - loss: 0.01426 - pearson: 0.8853 - lr: 2.2917923273898912e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01936 - pearson: 0.8457\n",
      "'best_value' is improved by 0.0020298061488847052! New 'best_value': 0.8457095035813078. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "342/342 - remain: 0:0:0 - loss: 0.01422 - pearson: 0.8855 - lr: 7.087165113121964e-08\n",
      "\n",
      "Training loss: 0.01422 - pearson: 0.8855\n",
      "Validation loss: 0.01936 - pearson: 0.8457\n",
      "Total time: 1:13:21\n",
      "\n",
      "Epoch 4/6\n",
      "\n",
      "100/342 - remain: 0:16:3 - loss: 0.01405 - pearson: 0.8918 - lr: 9.94102350542652e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01941 - pearson: 0.842\n",
      "\n",
      "200/342 - remain: 0:10:5 - loss: 0.01407 - pearson: 0.889 - lr: 9.444042969522029e-06\n",
      "300/342 - remain: 0:2:52 - loss: 0.0145 - pearson: 0.8854 - lr: 8.4893707345265e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01453 - pearson: 0.8848 - lr: 7.974146320430544e-06\n",
      "\n",
      "Training loss: 0.01453 - pearson: 0.8848\n",
      "Validation loss: 0.01936 - pearson: 0.8457\n",
      "Total time: 1:36:44\n",
      "\n",
      "Epoch 5/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01981 - pearson: 0.8454\n",
      "\n",
      "100/342 - remain: 0:18:3 - loss: 0.01141 - pearson: 0.9119 - lr: 6.547843559486482e-06\n",
      "200/342 - remain: 0:9:53 - loss: 0.01136 - pearson: 0.911 - lr: 4.962128490082072e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01882 - pearson: 0.8507\n",
      "'best_value' is improved by 0.005006212843992497! New 'best_value': 0.8507157164253003. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:2 - loss: 0.0114 - pearson: 0.9102 - lr: 3.38031380504396e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01126 - pearson: 0.9113 - lr: 2.756724203475174e-06\n",
      "\n",
      "Training loss: 0.01126 - pearson: 0.9113\n",
      "Validation loss: 0.01882 - pearson: 0.8507\n",
      "Total time: 2:1:18\n",
      "\n",
      "Epoch 6/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01856 - pearson: 0.8538\n",
      "'best_value' is improved by 0.003036756891556469! New 'best_value': 0.8537524733168568. Checkpoint path: './fold_2/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:19:31 - loss: 0.009102 - pearson: 0.9292 - lr: 1.4567824956831044e-06\n",
      "200/342 - remain: 0:10:5 - loss: 0.0091 - pearson: 0.9289 - lr: 5.217565303628785e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.0186 - pearson: 0.8533\n",
      "\n",
      "300/342 - remain: 0:3:2 - loss: 0.009017 - pearson: 0.929 - lr: 4.794457143692644e-08\n",
      "342/342 - remain: 0:0:0 - loss: 0.009046 - pearson: 0.9285 - lr: 2.5971524677537164e-11\n",
      "\n",
      "Training loss: 0.009046 - pearson: 0.9285\n",
      "Validation loss: 0.01856 - pearson: 0.8538\n",
      "Total time: 2:25:55\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 3/4\n",
      "\n",
      "Train samples: 27355\n",
      "Validation samples: 9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 6\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/6\n",
      "\n",
      "100/342 - remain: 0:15:44 - loss: 0.05904 - pearson: 0.287 - lr: 9.649122807017543e-06\n",
      "200/342 - remain: 0:9:1 - loss: 0.04467 - pearson: 0.5166 - lr: 9.760582915150719e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02381 - pearson: 0.8061\n",
      "'best_value' is improved by inf! New 'best_value': 0.8060586464962917. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:2:52 - loss: 0.03815 - pearson: 0.6072 - lr: 9.031210290080277e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.0364 - pearson: 0.6309 - lr: 8.59513134969601e-06\n",
      "\n",
      "Training loss: 0.0364 - pearson: 0.6309\n",
      "Validation loss: 0.02381 - pearson: 0.8061\n",
      "Total time: 0:23:11\n",
      "\n",
      "Epoch 2/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02037 - pearson: 0.8375\n",
      "'best_value' is improved by 0.031398481088068864! New 'best_value': 0.8374571275843605. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:58 - loss: 0.01897 - pearson: 0.8486 - lr: 7.309279104002865e-06\n",
      "200/342 - remain: 0:10:7 - loss: 0.0186 - pearson: 0.8502 - lr: 5.7855943521806924e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01902 - pearson: 0.8481\n",
      "'best_value' is improved by 0.010628292462132594! New 'best_value': 0.8480854200464931. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:4 - loss: 0.01833 - pearson: 0.8526 - lr: 4.1810012886451036e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01832 - pearson: 0.8521 - lr: 3.522814566610285e-06\n",
      "\n",
      "Training loss: 0.01832 - pearson: 0.8521\n",
      "Validation loss: 0.01902 - pearson: 0.8481\n",
      "Total time: 0:47:38\n",
      "\n",
      "Epoch 3/6\n",
      "\n",
      "100/342 - remain: 0:15:28 - loss: 0.01497 - pearson: 0.8801 - lr: 2.0857696856899236e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01827 - pearson: 0.8548\n",
      "'best_value' is improved by 0.00671545279146335! New 'best_value': 0.8548008728379565. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/342 - remain: 0:10:4 - loss: 0.01446 - pearson: 0.8844 - lr: 9.488611970697137e-07\n",
      "300/342 - remain: 0:2:53 - loss: 0.01427 - pearson: 0.8849 - lr: 2.2917923273898912e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01822 - pearson: 0.8551\n",
      "'best_value' is improved by 0.0003331022522563565! New 'best_value': 0.8551339750902128. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "342/342 - remain: 0:0:0 - loss: 0.01423 - pearson: 0.8855 - lr: 7.087165113121964e-08\n",
      "\n",
      "Training loss: 0.01423 - pearson: 0.8855\n",
      "Validation loss: 0.01822 - pearson: 0.8551\n",
      "Total time: 1:12:30\n",
      "\n",
      "Epoch 4/6\n",
      "\n",
      "100/342 - remain: 0:15:30 - loss: 0.01372 - pearson: 0.8892 - lr: 9.94102350542652e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01862 - pearson: 0.8542\n",
      "\n",
      "200/342 - remain: 0:9:48 - loss: 0.01429 - pearson: 0.8864 - lr: 9.444042969522029e-06\n",
      "300/342 - remain: 0:2:50 - loss: 0.01453 - pearson: 0.8841 - lr: 8.4893707345265e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01475 - pearson: 0.8829 - lr: 7.974146320430544e-06\n",
      "\n",
      "Training loss: 0.01475 - pearson: 0.8829\n",
      "Validation loss: 0.01822 - pearson: 0.8551\n",
      "Total time: 1:35:27\n",
      "\n",
      "Epoch 5/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01826 - pearson: 0.8578\n",
      "'best_value' is improved by 0.002670144540592778! New 'best_value': 0.8578041196308056. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:50 - loss: 0.01138 - pearson: 0.9089 - lr: 6.547843559486482e-06\n",
      "200/342 - remain: 0:10:5 - loss: 0.01135 - pearson: 0.9104 - lr: 4.962128490082072e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.0178 - pearson: 0.8605\n",
      "'best_value' is improved by 0.0026901311745035628! New 'best_value': 0.8604942508053092. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:4 - loss: 0.01133 - pearson: 0.9098 - lr: 3.38031380504396e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01138 - pearson: 0.9096 - lr: 2.756724203475174e-06\n",
      "\n",
      "Training loss: 0.01138 - pearson: 0.9096\n",
      "Validation loss: 0.0178 - pearson: 0.8605\n",
      "Total time: 2:0:2\n",
      "\n",
      "Epoch 6/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01727 - pearson: 0.8645\n",
      "'best_value' is improved by 0.0040246775130753365! New 'best_value': 0.8645189283183845. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:39 - loss: 0.008921 - pearson: 0.9302 - lr: 1.4567824956831044e-06\n",
      "200/342 - remain: 0:9:55 - loss: 0.009008 - pearson: 0.9282 - lr: 5.217565303628785e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01717 - pearson: 0.8652\n",
      "'best_value' is improved by 0.0006358351166133591! New 'best_value': 0.8651547634349979. Checkpoint path: './fold_3/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:5 - loss: 0.009124 - pearson: 0.9274 - lr: 4.794457143692644e-08\n",
      "342/342 - remain: 0:0:0 - loss: 0.009125 - pearson: 0.9277 - lr: 2.5971524677537164e-11\n",
      "\n",
      "Training loss: 0.009125 - pearson: 0.9277\n",
      "Validation loss: 0.01717 - pearson: 0.8652\n",
      "Total time: 2:24:49\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Fold 4/4\n",
      "\n",
      "Train samples: 27355\n",
      "Validation samples: 9118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'mask_predictions.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Checkpointing: True\n",
      "Epochs: 6\n",
      "Auto Mixed Precision: True\n",
      "Gradient norm: 1.0\n",
      "Gradient scaling: True\n",
      "Gradient accumulation steps: 1\n",
      "Validation steps: 200\n",
      "Device: cuda\n",
      "\n",
      "\n",
      "Epoch 1/6\n",
      "\n",
      "100/342 - remain: 0:15:23 - loss: 0.0622 - pearson: 0.2887 - lr: 9.649122807017543e-06\n",
      "200/342 - remain: 0:9:14 - loss: 0.04649 - pearson: 0.5168 - lr: 9.760582915150719e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02347 - pearson: 0.8048\n",
      "'best_value' is improved by inf! New 'best_value': 0.8048022948727197. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:2:54 - loss: 0.03951 - pearson: 0.6087 - lr: 9.031210290080277e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.03752 - pearson: 0.6322 - lr: 8.59513134969601e-06\n",
      "\n",
      "Training loss: 0.03752 - pearson: 0.6322\n",
      "Validation loss: 0.02347 - pearson: 0.8048\n",
      "Total time: 0:23:26\n",
      "\n",
      "Epoch 2/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02091 - pearson: 0.8329\n",
      "'best_value' is improved by 0.028114140792801834! New 'best_value': 0.8329164356655215. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:44 - loss: 0.01893 - pearson: 0.8444 - lr: 7.309279104002865e-06\n",
      "200/342 - remain: 0:10:10 - loss: 0.01844 - pearson: 0.8512 - lr: 5.7855943521806924e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.02007 - pearson: 0.8431\n",
      "'best_value' is improved by 0.010180569145496143! New 'best_value': 0.8430970048110177. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:7 - loss: 0.01839 - pearson: 0.8518 - lr: 4.1810012886451036e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.0182 - pearson: 0.8534 - lr: 3.522814566610285e-06\n",
      "\n",
      "Training loss: 0.0182 - pearson: 0.8534\n",
      "Validation loss: 0.02007 - pearson: 0.8431\n",
      "Total time: 0:48:20\n",
      "\n",
      "Epoch 3/6\n",
      "\n",
      "100/342 - remain: 0:15:28 - loss: 0.01431 - pearson: 0.8855 - lr: 2.0857696856899236e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01884 - pearson: 0.8495\n",
      "'best_value' is improved by 0.006427031321824539! New 'best_value': 0.8495240361328422. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "200/342 - remain: 0:10:19 - loss: 0.01429 - pearson: 0.8843 - lr: 9.488611970697137e-07\n",
      "300/342 - remain: 0:2:54 - loss: 0.01423 - pearson: 0.886 - lr: 2.2917923273898912e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01846 - pearson: 0.8515\n",
      "'best_value' is improved by 0.0019583021327860273! New 'best_value': 0.8514823382656282. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "342/342 - remain: 0:0:0 - loss: 0.01418 - pearson: 0.8862 - lr: 7.087165113121964e-08\n",
      "\n",
      "Training loss: 0.01418 - pearson: 0.8862\n",
      "Validation loss: 0.01846 - pearson: 0.8515\n",
      "Total time: 1:13:12\n",
      "\n",
      "Epoch 4/6\n",
      "\n",
      "100/342 - remain: 0:15:32 - loss: 0.01362 - pearson: 0.8903 - lr: 9.94102350542652e-06\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01894 - pearson: 0.8472\n",
      "\n",
      "200/342 - remain: 0:9:59 - loss: 0.01414 - pearson: 0.8882 - lr: 9.444042969522029e-06\n",
      "300/342 - remain: 0:2:51 - loss: 0.01443 - pearson: 0.8854 - lr: 8.4893707345265e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01444 - pearson: 0.8849 - lr: 7.974146320430544e-06\n",
      "\n",
      "Training loss: 0.01444 - pearson: 0.8849\n",
      "Validation loss: 0.01846 - pearson: 0.8515\n",
      "Total time: 1:36:24\n",
      "\n",
      "Epoch 5/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.0181 - pearson: 0.8549\n",
      "'best_value' is improved by 0.0033976016217970306! New 'best_value': 0.8548799398874253. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:19:9 - loss: 0.01156 - pearson: 0.9101 - lr: 6.547843559486482e-06\n",
      "200/342 - remain: 0:10:8 - loss: 0.01142 - pearson: 0.9113 - lr: 4.962128490082072e-06\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01797 - pearson: 0.8571\n",
      "'best_value' is improved by 0.002221766493034072! New 'best_value': 0.8571017063804593. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:6 - loss: 0.0113 - pearson: 0.9115 - lr: 3.38031380504396e-06\n",
      "342/342 - remain: 0:0:0 - loss: 0.01125 - pearson: 0.9118 - lr: 2.756724203475174e-06\n",
      "\n",
      "Training loss: 0.01125 - pearson: 0.9118\n",
      "Validation loss: 0.01797 - pearson: 0.8571\n",
      "Total time: 2:1:15\n",
      "\n",
      "Epoch 6/6\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01793 - pearson: 0.8583\n",
      "'best_value' is improved by 0.0012188127417834815! New 'best_value': 0.8583205191222428. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "100/342 - remain: 0:18:54 - loss: 0.009419 - pearson: 0.9265 - lr: 1.4567824956831044e-06\n",
      "200/342 - remain: 0:10:12 - loss: 0.009192 - pearson: 0.9279 - lr: 5.217565303628785e-07\n",
      "\n",
      "[Validation] 57/57 - remain: 0:0:0 - loss: 0.01785 - pearson: 0.8587\n",
      "'best_value' is improved by 0.00036881946603484206! New 'best_value': 0.8586893385882777. Checkpoint path: './fold_4/checkpoints/checkpoint.pth'.\n",
      "\n",
      "300/342 - remain: 0:3:7 - loss: 0.009145 - pearson: 0.9279 - lr: 4.794457143692644e-08\n",
      "342/342 - remain: 0:0:0 - loss: 0.009115 - pearson: 0.9282 - lr: 2.5971524677537164e-11\n",
      "\n",
      "Training loss: 0.009115 - pearson: 0.9282\n",
      "Validation loss: 0.01785 - pearson: 0.8587\n",
      "Total time: 2:26:8\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CV scores: [0.8596 0.8538 0.8652 0.8587]\n",
      "CV mean: 0.8593\n",
      "CV std: 0.004047\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "oof_data_frame = pd.DataFrame()\n",
    "for fold in range(1, config.folds + 1):\n",
    "    print(f\"Fold {fold}/{config.folds}\", end=\"\\n\"*2)\n",
    "    \n",
    "    fold_directory = os.path.join(config.output_directory, f\"fold_{fold}\")    \n",
    "    make_directory(fold_directory)\n",
    "    model_path = os.path.join(fold_directory, \"model.pth\")\n",
    "    model_config_path = os.path.join(fold_directory, \"model_config.json\")\n",
    "    checkpoints_directory = os.path.join(fold_directory, \"checkpoints/\")\n",
    "    make_directory(checkpoints_directory)\n",
    "    \n",
    "    collator = Collator(tokenizer=tokenizer, max_length=config.max_length)\n",
    "    \n",
    "    train_fold = train[~train[\"fold\"].isin([fold])]\n",
    "    train_dataset = Dataset(texts=train_fold[\"text\"].values, \n",
    "                            pair_texts=train_fold[\"target\"].values,\n",
    "                            contexts=train_fold[\"title\"].values,\n",
    "                            targets=train_fold[\"score\"].values, \n",
    "                            max_length=config.max_length,\n",
    "                            sep=tokenizer.sep_token,\n",
    "                            tokenizer=tokenizer)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, \n",
    "                              batch_size=config.batch_size, \n",
    "                              num_workers=config.num_workers,\n",
    "                              pin_memory=config.pin_memory,\n",
    "                              collate_fn=collator,\n",
    "                              shuffle=True, \n",
    "                              drop_last=False)\n",
    "    \n",
    "    print(f\"Train samples: {len(train_dataset)}\")\n",
    "    \n",
    "    validation_fold = train[train[\"fold\"].isin([fold])]\n",
    "    validation_dataset = Dataset(texts=validation_fold[\"text\"].values, \n",
    "                                 pair_texts=validation_fold[\"target\"].values,\n",
    "                                 contexts=validation_fold[\"title\"].values,\n",
    "                                 targets=validation_fold[\"score\"].values,\n",
    "                                 max_length=config.max_length,\n",
    "                                 sep=tokenizer.sep_token,\n",
    "                                 tokenizer=tokenizer)\n",
    "    \n",
    "    validation_loader = DataLoader(dataset=validation_dataset, \n",
    "                                   batch_size=config.batch_size*2, \n",
    "                                   num_workers=config.num_workers,\n",
    "                                   pin_memory=config.pin_memory,\n",
    "                                   collate_fn=collator,\n",
    "                                   shuffle=False, \n",
    "                                   drop_last=False)\n",
    "    \n",
    "    print(f\"Validation samples: {len(validation_dataset)}\")\n",
    "    \n",
    "    \n",
    "    model = Model(**config.model)\n",
    "    model.config.to_json_file(model_config_path)\n",
    "    model_parameters = model.parameters()\n",
    "    \n",
    "    optimizer = get_optimizer(**config.optimizer, model_parameters=model_parameters)\n",
    "    \n",
    "    if \"scheduler\" in config:\n",
    "        training_steps = len(train_loader) * config.epochs\n",
    "        training_steps = int(training_steps // config.gradient_accumulation_steps)\n",
    "        \n",
    "        config.scheduler.parameters.num_training_steps = training_steps\n",
    "        config.scheduler.parameters.num_warmup_steps = training_steps * config.get(\"warmup\", 0)\n",
    "        scheduler = transformers.get_cosine_with_hard_restarts_schedule_with_warmup(optimizer=optimizer,num_warmup_steps=training_steps * config.get(\"warmup\", 0),num_training_steps=training_steps,num_cycles=2,last_epoch=-1)\n",
    "\n",
    "    else:\n",
    "        scheduler = None\n",
    "        \n",
    "    model_checkpoint = ModelCheckpoint(mode=\"max\", \n",
    "                                       delta=config.delta, \n",
    "                                       directory=checkpoints_directory, \n",
    "                                       overwriting=True, \n",
    "                                       filename_format=\"checkpoint.pth\", \n",
    "                                       num_candidates=1)\n",
    "\n",
    "\n",
    "    if WANDB: wandb.init(group=EXPERIMENT_NAME, name=f\"Fold {fold}\", config=config)\n",
    "    (train_loss, train_metrics), (validation_loss, validation_metrics, validation_outputs) = training_loop(model=model, \n",
    "                                                                                                           optimizer=optimizer, \n",
    "                                                                                                           scheduler=scheduler,\n",
    "                                                                                                           scheduling_after=config.scheduling_after,\n",
    "                                                                                                           train_loader=train_loader,\n",
    "                                                                                                           validation_loader=validation_loader,\n",
    "                                                                                                           epochs=config.epochs, \n",
    "                                                                                                           gradient_accumulation_steps=config.gradient_accumulation_steps, \n",
    "                                                                                                           gradient_scaling=config.gradient_scaling, \n",
    "                                                                                                           gradient_norm=config.gradient_norm, \n",
    "                                                                                                           validation_steps=config.validation_steps, \n",
    "                                                                                                           amp=config.amp,\n",
    "                                                                                                           debug=config.debug, \n",
    "                                                                                                           verbose=config.verbose, \n",
    "                                                                                                           device=config.device, \n",
    "                                                                                                           recalculate_metrics_at_end=True, \n",
    "                                                                                                           return_validation_outputs=True, \n",
    "                                                                                                           logger=[\"print\", \"wandb\"], \n",
    "                                                                                                           decimals=config.decimals)\n",
    "    \n",
    "    if WANDB: wandb.finish()\n",
    "    \n",
    "    if config.save_model:\n",
    "        model_state = model.state_dict()\n",
    "        torch.save(model_state, model_path)\n",
    "        print(f\"Model's path: {model_path}\")\n",
    "    \n",
    "    validation_fold[\"prediction\"] = validation_outputs.to(\"cpu\").numpy()\n",
    "    oof_data_frame = pd.concat([oof_data_frame, validation_fold])\n",
    "        \n",
    "    cv_monitor_value = validation_loss if config.cv_monitor_value == \"loss\" else validation_metrics.get(config.cv_monitor_value, np.nan)\n",
    "    cv_scores.append(cv_monitor_value)\n",
    "    \n",
    "    \n",
    "    del model, optimizer, validation_outputs, train_fold, validation_fold\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(end=\"\\n\"*5)\n",
    "    \n",
    "cv_scores = np.array(cv_scores).round(config.decimals)\n",
    "np.save(\"cv_scores.npy\", cv_scores)\n",
    "oof_data_frame.to_pickle(\"oof.pkl\")\n",
    "configuration_path = config.to_json(\"configuration.json\")\n",
    "\n",
    "print(f\"CV scores: {cv_scores}\")\n",
    "print(f\"CV mean: {cv_scores.mean():.{config.decimals}}\")\n",
    "print(f\"CV std: {cv_scores.std():.{config.decimals}}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af175732",
   "metadata": {
    "papermill": {
     "duration": 0.101897,
     "end_time": "2022-06-19T12:37:33.721800",
     "exception": false,
     "start_time": "2022-06-19T12:37:33.619903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35054.241308,
   "end_time": "2022-06-19T12:37:37.306727",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-19T02:53:23.065419",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "026e0caf760b4848b48555c5e4535db7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "048f857e68e549b0bf50391e3e44a212": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "09e538ffeade4d799c3a66f9b62f376c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bc583225ca744845bf047242e039c50a",
       "placeholder": "​",
       "style": "IPY_MODEL_670313e940fb4f0f99345785b81fa090",
       "value": "Downloading: 100%"
      }
     },
     "0bc05b933322480f812dd4957e8ce830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0ccc5b21fdf74e91854bb68c6a982bed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c92d5310ab9a4a6bb3543f5b2856f946",
       "placeholder": "​",
       "style": "IPY_MODEL_a480799f34dd44258358eb2965bc5d96",
       "value": "Downloading: 100%"
      }
     },
     "1650fa9a77814a1c8ebf89d13a684f1f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6a288457a9be454aa61f19b9b9bc2f66",
       "placeholder": "​",
       "style": "IPY_MODEL_0bc05b933322480f812dd4957e8ce830",
       "value": " 52.0/52.0 [00:00&lt;00:00, 1.66kB/s]"
      }
     },
     "1ed9175234704715a95720a48ee48b62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_87c7d227a3284428ba6689766e15f6da",
       "max": 873673253.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c7c1703530f14e7ab3f254c8652dd5ce",
       "value": 873673253.0
      }
     },
     "2fc16b9fc61e4248b99a190bb17b04a6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30b9a2cd6ad247839799b5446f1a63e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "37afff43ded54211831d241365a738f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_49b615cf58804e83a4ad9454aa13dcb4",
       "max": 52.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8a43ba4589254ce28d8fcbb52499ef85",
       "value": 52.0
      }
     },
     "3a3b9074e2a94885928e32a0950a6f4c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a5da48719f74459a6cc6d7e0c4e4ddf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d538753a4cdf43d3862b74ea052a7acd",
        "IPY_MODEL_4d4b6b3c6e434a848b95c39ca29eff08",
        "IPY_MODEL_d48c9cad47e24e14bc854f46102f0de3"
       ],
       "layout": "IPY_MODEL_6a5d3d2cf35d47a3b77d437bb0edb130"
      }
     },
     "49b615cf58804e83a4ad9454aa13dcb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d4b6b3c6e434a848b95c39ca29eff08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7374c306bafc4585bb7e778109b5b384",
       "max": 580.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_56ae9999af0d4feab0250f8fd35488e4",
       "value": 580.0
      }
     },
     "53112a5dc8b147ea9628f77b01dd3106": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "56ae9999af0d4feab0250f8fd35488e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "64f12bb207e645b68b241da04e94e13f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "670313e940fb4f0f99345785b81fa090": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6a288457a9be454aa61f19b9b9bc2f66": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a5d3d2cf35d47a3b77d437bb0edb130": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a81c1f0083244a9b2c1e2d281c00b37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ccc5b21fdf74e91854bb68c6a982bed",
        "IPY_MODEL_1ed9175234704715a95720a48ee48b62",
        "IPY_MODEL_ed06843b492e40af91ed3f06a6cff4a4"
       ],
       "layout": "IPY_MODEL_026e0caf760b4848b48555c5e4535db7"
      }
     },
     "6b6b21d8cbdb49888dc2ad5a2c93a24e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7374c306bafc4585bb7e778109b5b384": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "87c7d227a3284428ba6689766e15f6da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8a43ba4589254ce28d8fcbb52499ef85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8da3bd4dcf3b4c8ca994bbbedfa1a542": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f893bc24e6c54d11a9988a51289211cf",
        "IPY_MODEL_37afff43ded54211831d241365a738f0",
        "IPY_MODEL_1650fa9a77814a1c8ebf89d13a684f1f"
       ],
       "layout": "IPY_MODEL_64f12bb207e645b68b241da04e94e13f"
      }
     },
     "957ca630fe2f4436b48cf0b62c7425ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9eb1d2eed1454ec8afc4f1316506c426": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a435bd4c63c94374a199e9b0e5f0fa84": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_53112a5dc8b147ea9628f77b01dd3106",
       "placeholder": "​",
       "style": "IPY_MODEL_f8174ac5393e47ffb534525124443612",
       "value": " 2.35M/2.35M [00:00&lt;00:00, 3.63MB/s]"
      }
     },
     "a480799f34dd44258358eb2965bc5d96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a852385b9bee439999394a7010e376ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b09bb6fbee554f6f8b1712364480d512": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bf3b01f95709463e8a46e3d07d00b4b6",
       "max": 2464616.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_30b9a2cd6ad247839799b5446f1a63e6",
       "value": 2464616.0
      }
     },
     "bc583225ca744845bf047242e039c50a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bf3b01f95709463e8a46e3d07d00b4b6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7c1703530f14e7ab3f254c8652dd5ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c92d5310ab9a4a6bb3543f5b2856f946": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cacb8f30dec349358d888a1881d5b085": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d48c9cad47e24e14bc854f46102f0de3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbcdf110a661464ab887423354dfbc2f",
       "placeholder": "​",
       "style": "IPY_MODEL_a852385b9bee439999394a7010e376ba",
       "value": " 580/580 [00:00&lt;00:00, 19.7kB/s]"
      }
     },
     "d538753a4cdf43d3862b74ea052a7acd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9eb1d2eed1454ec8afc4f1316506c426",
       "placeholder": "​",
       "style": "IPY_MODEL_048f857e68e549b0bf50391e3e44a212",
       "value": "Downloading: 100%"
      }
     },
     "da9599ca264843b194063d0477803ab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_09e538ffeade4d799c3a66f9b62f376c",
        "IPY_MODEL_b09bb6fbee554f6f8b1712364480d512",
        "IPY_MODEL_a435bd4c63c94374a199e9b0e5f0fa84"
       ],
       "layout": "IPY_MODEL_6b6b21d8cbdb49888dc2ad5a2c93a24e"
      }
     },
     "ed06843b492e40af91ed3f06a6cff4a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2fc16b9fc61e4248b99a190bb17b04a6",
       "placeholder": "​",
       "style": "IPY_MODEL_3a3b9074e2a94885928e32a0950a6f4c",
       "value": " 833M/833M [00:38&lt;00:00, 23.6MB/s]"
      }
     },
     "f8174ac5393e47ffb534525124443612": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f893bc24e6c54d11a9988a51289211cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_957ca630fe2f4436b48cf0b62c7425ad",
       "placeholder": "​",
       "style": "IPY_MODEL_cacb8f30dec349358d888a1881d5b085",
       "value": "Downloading: 100%"
      }
     },
     "fbcdf110a661464ab887423354dfbc2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
